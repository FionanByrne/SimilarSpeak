{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Execution times and average distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:/Users/fiona/Desktop/SimilarSpeak/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_generator import closest_edits\n",
    "from word_distance import WordDistance\n",
    "from syllabifier import Syllabifier\n",
    "from trigram_model import pronouncable\n",
    "import matplotlib.pyplot as plt\n",
    "import datamuse\n",
    "import operator\n",
    "import time\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations, islice, accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D', 'AO', 'G']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Words:[['F', 'AO', 'L'], ['F', 'AO', 'R'], ['F', 'AO'], ['HH', 'AO', 'F'], ['HH', 'AO', 'K'], ['HH', 'AO', 'L'], ['HH', 'AO', 'R'], ['HH', 'AO'], ['TH', 'AO', 'L'], ['TH', 'AO', 'R'], ['TH', 'AO', 'T'], ['TH', 'AO'], ['W', 'AO', 'L'], ['W', 'AO', 'R'], ['W', 'AO'], ['AO', 'L'], ['AO', 'R'], ['AO']]\n",
      "Calculating word dist for ['F', 'AO', 'L']                  (1/18)\n",
      "Calculating word dist for ['F', 'AO', 'R']                  (2/18)\n",
      "Calculating word dist for ['F', 'AO']                  (3/18)\n",
      "Calculating word dist for ['HH', 'AO', 'F']                  (4/18)\n",
      "Calculating word dist for ['HH', 'AO', 'K']                  (5/18)\n",
      "Calculating word dist for ['HH', 'AO', 'L']                  (6/18)\n",
      "Calculating word dist for ['HH', 'AO', 'R']                  (7/18)\n",
      "Calculating word dist for ['HH', 'AO']                  (8/18)\n",
      "Calculating word dist for ['TH', 'AO', 'L']                  (9/18)\n",
      "Calculating word dist for ['TH', 'AO', 'R']                  (10/18)\n",
      "Calculating word dist for ['TH', 'AO', 'T']                  (11/18)\n",
      "Calculating word dist for ['TH', 'AO']                  (12/18)\n",
      "Calculating word dist for ['W', 'AO', 'L']                  (13/18)\n",
      "Calculating word dist for ['W', 'AO', 'R']                  (14/18)\n",
      "Calculating word dist for ['W', 'AO']                  (15/18)\n",
      "Calculating word dist for ['AO', 'L']                  (16/18)\n",
      "Calculating word dist for ['AO', 'R']                  (17/18)\n"
     ]
    }
   ],
   "source": [
    "syllab = Syllabifier()\n",
    "sylls_input = syllab.to_syllables(syllab.to_phoneme(\"dog\"))\n",
    "print(sylls_input)\n",
    "sim_words, average_dist, ex_time = closest_edits(\"dog\", sylls_input, experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_test = [\"dog\", \"cat\", \"rocket\", \"testing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1 = pd.DataFrame(columns=[\"time\", \"average_dist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator1(word_name):\n",
    "    syllab = Syllabifier()\n",
    "    sylls_input = syllab.to_syllables(syllab.to_phoneme(word_name))\n",
    "    sim_words, average_dist, ex_time = closest_edits(word_name, sylls_input)\n",
    "    return ex_time, average_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word_name in words_to_test:\n",
    "    ex_time, average_dist = test_generator1(word_name)\n",
    "    experiment1.at[word_name] = {\"time\":float(ex_time), \"average_dist\": str(round(average_dist, 3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment1.to_csv(r'tests/experiment1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoneme to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.9821428571428571\n",
    "round(x, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = [\"D\", \"AW\", \"G\", \"ER\"]\n",
    "#syllables = list(map(' '.join, syllables))\n",
    "dictionary = [[\"D AW G E R\"],[\"D AW G\"], [\"E R\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word, indexes):\n",
    "    boundary = 0\n",
    "    x = []\n",
    "    i = 0\n",
    "    for i in range(len(indexes)):\n",
    "        split = indexes[i]\n",
    "        x.append(word[boundary:split])\n",
    "        boundary = split\n",
    "    x.append(word[boundary:])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"ABCDE\"\n",
    "#powerset((range(1, len(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_indexes = powerset((range(1, len(syllables))))\n",
    "for s in split_indexes:\n",
    "    print(split(syllables, s)) # Checi if in dictionary\n",
    "    #y = list(filter(lambda x: all(x in dictionary), split(syllables, s))) # Checi if in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sizes(n):\n",
    "    \"\"\"\n",
    "    Generate all integer partitions of n\n",
    "    in reverse lexicographic order\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        yield []\n",
    "        return\n",
    "    for p in split_sizes(n - 1):\n",
    "        if len(p) == 1 or (len(p) > 1 and p[-1] < p[-2]):\n",
    "            p[-1] += 1\n",
    "            yield p\n",
    "            p[-1] -= 1\n",
    "        p.append(1)\n",
    "        yield p\n",
    "        p.pop()\n",
    "\n",
    "def valid_words(syllables, lengths):\n",
    "    splits = []\n",
    "    for l in lengths:\n",
    "        splits.append([syllables[x - y: x] for x, y in zip(accumulate(l), l)])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = split_sizes(len(syllables))\n",
    "print(list(lengths))\n",
    "#for l in lengths:\n",
    "for i in valid_words(syllables, lengths):\n",
    "    #i = list(map(' '.join, syllables))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with RZ\n",
    "def compare_RZ(target, num_words): \n",
    "    api = datamuse.Datamuse()\n",
    "    s = Syllabifier()\n",
    "    wd = WordDistance()\n",
    "    target_p = s.to_syllables(s.to_phoneme(target))\n",
    "    word_list = api.words(sl=target, max=num_words)\n",
    "    for entry in word_list:\n",
    "        sim_word = entry[\"word\"]\n",
    "        score = entry[\"score\"]\n",
    "        if s.is_valid(sim_word):\n",
    "            sim_p = s.to_syllables(s.to_phoneme(sim_word))\n",
    "            print(wd.word_dist(target_p, sim_p, True), \"SCORE=\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_RZ(\"incredible\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = datamuse.Datamuse()\n",
    "api.words(sl=\"incredible\", max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mapper.phoneme_to_text(['T', 'AE', 'S', 'T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pronouncable(['K', 'AE', 'T'], 0.03, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = text_mapper.phoneme_to_text(['T', 'UW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in x.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
