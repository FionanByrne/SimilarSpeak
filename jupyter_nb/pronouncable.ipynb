{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "from more_itertools import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_phoneme(input_word):\n",
    "    \"\"\"\n",
    "    This function responds to a request for /api/words\n",
    "    with the complete lists of words\n",
    "\n",
    "    :param: input_word: word to convert to arpabet\n",
    "    :returns:        string of translated word\n",
    "    \"\"\"\n",
    "    # Generate list of phonemes for the word\n",
    "    phones = []\n",
    "\n",
    "    # Take first variation of phoneme representations\n",
    "    phones_w = arpabet[input_word][0]\n",
    "    for p in phones_w:\n",
    "        # omits the numbers from phone labels\n",
    "        new_p = p[:2]\n",
    "        phones.append(new_p)\n",
    "\n",
    "    return phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_syllables(input_phoneme):\n",
    "    # Phoneme sonority values\n",
    "    syl_dic = {\n",
    "        'AA': 11,\n",
    "        'AE': 11,\n",
    "        'AH': 11,\n",
    "        'AO': 11,\n",
    "        'AW': 11,\n",
    "        'AY': 11,\n",
    "        'EH': 11,\n",
    "        'ER': 11,\n",
    "        'EY': 11,\n",
    "        'IH': 11,\n",
    "        'IY': 11,\n",
    "        'OW': 11,\n",
    "        'OY': 11,\n",
    "        'UH': 11,\n",
    "        'UW': 11,\n",
    "        'Y': 10,\n",
    "        'W': 10,\n",
    "        'R': 9,\n",
    "        'L': 8,\n",
    "        'M': 7,\n",
    "        'N': 7,\n",
    "        'NG': 7,\n",
    "        'Z': 6,\n",
    "        'ZH': 6,\n",
    "        'V': 6,\n",
    "        'DH': 6,\n",
    "        'S': 5,\n",
    "        'SH': 5,\n",
    "        'F': 5,\n",
    "        'TH': 5,\n",
    "        'HH': 5,\n",
    "        'JH': 4,\n",
    "        'CH': 3,\n",
    "        'B': 2,\n",
    "        'D': 2,\n",
    "        'G': 2,\n",
    "        'P': 1,\n",
    "        'T': 1,\n",
    "        'K': 1\n",
    "    }\n",
    "\n",
    "    # Split phoneme lists into syllables\n",
    "    syllables = []\n",
    "    phones = []\n",
    "    phones.append(input_phoneme)\n",
    "    for word in phones:\n",
    "        boundary = 0\n",
    "        for i in range(1, len(word)):\n",
    "            if ((word[i] == 'K'\n",
    "                    and word[i-1] != 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 8)\n",
    "                or (word[i] == 'T'\n",
    "                    and word[i-1] != 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 9)\n",
    "                or (word[i] == 'P'\n",
    "                    and word[i-1] != 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 8\n",
    "                    and word[i+1] != 'W')\n",
    "                or (word[i] == 'B'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 8\n",
    "                    and word[i+1] != 'W')\n",
    "                or (word[i] == 'G'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 8\n",
    "                    and not(word[i+1] in ['W', 'Y']))\n",
    "                or (word[i] == 'D'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 9)\n",
    "                or (word[i] in ['CH', 'JH', 'HH', 'SH', 'DH', 'ZH', 'Z']\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'TH'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 9\n",
    "                    and word[i+1] != 'Y')\n",
    "                or (word[i] in ['F', 'V']\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 8)\n",
    "                or (word[i] in ['N', 'M']\n",
    "                    and word[i-1] != 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'L'\n",
    "                    and not(word[i-1]\n",
    "                    in ['K', 'P', 'G', 'B', 'F', 'S', 'V'])\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'R'\n",
    "                    and not(word[i-1]\n",
    "                    in ['K', 'T', 'P', 'G', 'D', 'B', 'F', 'V'])\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'W'\n",
    "                    and not (word[i-1] in ['K', 'T', 'D', 'TH', 'DH'])\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'Y'\n",
    "                    and not (word[i-1] in ['K', 'P', 'F', 'V', 'B'])\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] == 11)\n",
    "                or (word[i] == 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and syl_dic[word[i+1]] >= 7)\n",
    "                or (word[i] == 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and word[i+1] == 'T'\n",
    "                    and i+2 < len(word)\n",
    "                    and syl_dic[word[i+2]] >= 9)\n",
    "                or (word[i] == 'S'\n",
    "                    and i+1 < len(word)\n",
    "                    and (word[i+1] == 'K' or word[i+1] == 'P')\n",
    "                    and i+2 < len(word) and syl_dic[word[i+2]] >= 8)\n",
    "                or (syl_dic[word[i]] == 11\n",
    "                    and (syl_dic[word[i-1]] == 11 or word[i-1] == 'NG'))):\n",
    "                syllables.append(word[boundary:i])\n",
    "                boundary = i\n",
    "\n",
    "        syllables.append(word[boundary:])\n",
    "        return syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"syllables.txt\"\n",
    "if os.path.exists(fname):\n",
    "    os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sylls = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fname, \"w+\") as f:\n",
    "    for word in arpabet:\n",
    "        phoneme_word = to_phoneme(word)\n",
    "        syllables_list = to_syllables(phoneme_word)\n",
    "        for _syll in syllables_list:\n",
    "            if _syll not in unique_sylls:\n",
    "                unique_sylls.append(_syll)\n",
    "                for _phoneme in _syll:\n",
    "                        f.write(_phoneme + \" \")\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D', 'AY'], ['AH', 'T', 'L']]\n"
     ]
    }
   ],
   "source": [
    "#Find obsure phoneme pairs:\n",
    "for word in arpabet:\n",
    "    phoneme_word = to_phoneme(word)\n",
    "    syllables_list = to_syllables(phoneme_word)\n",
    "    for syll in syllables_list:\n",
    "        for p1,p2 in pairwise(syll):\n",
    "            if p1==\"T\" and p2==\"L\":\n",
    "                print(syllables_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create markov model for training using syllables file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_chars = [i[0] for i in cmudict.phones()]\n",
    "#accepted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA': 0,\n",
       " 'AE': 1,\n",
       " 'AH': 2,\n",
       " 'AO': 3,\n",
       " 'AW': 4,\n",
       " 'AY': 5,\n",
       " 'B': 6,\n",
       " 'CH': 7,\n",
       " 'D': 8,\n",
       " 'DH': 9,\n",
       " 'EH': 10,\n",
       " 'ER': 11,\n",
       " 'EY': 12,\n",
       " 'F': 13,\n",
       " 'G': 14,\n",
       " 'HH': 15,\n",
       " 'IH': 16,\n",
       " 'IY': 17,\n",
       " 'JH': 18,\n",
       " 'K': 19,\n",
       " 'L': 20,\n",
       " 'M': 21,\n",
       " 'N': 22,\n",
       " 'NG': 23,\n",
       " 'OW': 24,\n",
       " 'OY': 25,\n",
       " 'P': 26,\n",
       " 'R': 27,\n",
       " 'S': 28,\n",
       " 'SH': 29,\n",
       " 'T': 30,\n",
       " 'TH': 31,\n",
       " 'UH': 32,\n",
       " 'UW': 33,\n",
       " 'V': 34,\n",
       " 'W': 35,\n",
       " 'Y': 36,\n",
       " 'Z': 37,\n",
       " 'ZH': 38}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = dict([(char, idx) for idx, char in enumerate(accepted_chars)])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(line):\n",
    "    \"\"\" Return only the subset of chars from accepted_chars.\n",
    "    This helps keep the  model relatively small by ignoring punctuation,\n",
    "    infrequenty symbols, etc. \"\"\"\n",
    "    return [c.lower() for c in line if c.lower() in accepted_chars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(n, l):\n",
    "    \"\"\" Return all n grams from l after normalizing \"\"\"\n",
    "    print(\"REST\")\n",
    "    filtered = normalize(l)\n",
    "    for start in range(0, len(filtered) - n + 1):\n",
    "        yield ''.join(filtered[start:start + n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_transition_prob(l, log_prob_mat):\n",
    "    \"\"\" Return the average transition prob from l through log_prob_mat. \"\"\"\n",
    "    log_prob = 0.0\n",
    "    transition_ct = 0\n",
    "    for a, b in ngram(2, l):\n",
    "        log_prob += log_prob_mat[pos[a]][pos[b]]\n",
    "        transition_ct += 1\n",
    "    # The exponentiation translates from log probs to probs.\n",
    "    return math.exp(log_prob / (transition_ct or 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(accepted_chars)\n",
    "counts = [[2 for i in range(k)] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object ngram at 0x0000024A80488C00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(2, \"LINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count transitions from big text file, taken\n",
    "for line in open('syllables.txt'):\n",
    "    syllables = line.split()\n",
    "    for a, b in ngram(2, syllables):\n",
    "        counts[pos[a]][pos[b]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(counts):\n",
    "    s = float(sum(row))\n",
    "    for j in range(len(row)):\n",
    "        row[j] = math.log(row[j] / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.018782003473122023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'mat': counts, 'thresh': thresh}, open('phon_model.pki', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pickle.load(open('.pki', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ers\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "word = input()\n",
    "print(avg_transition_prob(word, counts) > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
