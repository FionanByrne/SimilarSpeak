{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cmudict\n",
    "from nltk import ngrams\n",
    "from nltk import word_tokenize \n",
    "import nltk \n",
    "from itertools import permutations\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_phonemes = [i[0] for i in cmudict.phones()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleDumpsPath = \"pickleDumps/\"\n",
    "syllablesPath = \"syllables.pki\"\n",
    "phonemeCondProbsPath = pickleDumps + \"phonemeCondProbs.pki\"\n",
    "bigramsDictPath = pickleDumpsPath + \"bigramsDict.pki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsDict = dict([(char, 0) for char in accepted_phonemes])\n",
    "#unigramsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible phoneme pairs\n",
    "phoneme_pairs = list(permutations(accepted_phonemes, 2))\n",
    "#phoneme_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all possible pairs\n",
    "bigramsDict = dict([(char, 0) for char in phoneme_pairs])\n",
    "condProbsDict = dict([(char, 0) for char in phoneme_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickleDumpsPath+syllablesPath, \"rb\") as f:\n",
    "    all_syllables = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in all_syllables:\n",
    "    #line_split = nltk.word_tokenize(line)\n",
    "\n",
    "    # Count unigrams (phonemes)\n",
    "    for phoneme in line:\n",
    "        unigramsDict[phoneme] += 1\n",
    "\n",
    "    # Count bigrams: {\"AH T\" : 1, \"AH K\" : 3, ...}\n",
    "    bigrams = list(ngrams(line, 2))\n",
    "    for bigram in bigrams:\n",
    "        #key = (p1, p2)\n",
    "        #print(key)\n",
    "        if bigram in bigramsDict:\n",
    "            bigramsDict[bigram] += 1\n",
    "        else:\n",
    "            bigramsDict[bigram] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in sorted(unigramsDict, key=unigramsDict.get, reverse=True):\n",
    "#     print (p,\":\", unigramsDict[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p, q in sorted(bigramsDict, key=bigramsDict.get, reverse=True):\n",
    "#     print (p,q,\":\", bigramsDict[(p,q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, p2 in bigramsDict:\n",
    "    count = bigramsDict[(p1, p2)]\n",
    "    cProb = count*1.0 / unigramsDict[p1]\n",
    "    condProbsDict[(p1, p2)] = cProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(phonemeCondProbsPath, \"wb\") as f:\n",
    "    pickle.dump(condProbsDict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "import heapq\n",
    "import cmudict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleDumpsPath = \"pickleDumps/\"\n",
    "phonemeCondProbsPath = pickleDumps + \"phonemeCondProbs.pki\"\n",
    "bigramsDictPath = pickleDumpsPath + \"bigramsDict.pki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(phonemeCondProbsPath, \"rb\") as f:\n",
    "    condProbsDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouncable(syllable: str, thresh: float):\n",
    "    \"\"\"\n",
    "    :param syllable: Syllable to test [\"AH K T]\n",
    "    :param thresh: Minimum acceptable value for bigram conditional prob \n",
    "    :returns: True if syllable is pronouncable\n",
    "    \"\"\"\n",
    "    syllable_split = nltk.word_tokenize(syllable)\n",
    "    phoneme_consonants = [i[0] for i in cmudict.phones() if not i[1] == ['vowel']]\n",
    "    if len(syllable_split) == 0: # Emtpy Syllable\n",
    "        return True\n",
    "    if all(p in phoneme_consonants for p in syllable_split):  #No vowel sounds\n",
    "        return False\n",
    "    else:\n",
    "        bigrams = list(ngrams(syllable_split, 2))\n",
    "        # Compute conditional probabilities for phoneme bigrams\n",
    "        cond_probs = list(map(lambda pair: condProbsDict[pair], bigrams))\n",
    "        # Are all cond probs above threshold value\n",
    "        return all(cond_prob > thresh for cond_prob in cond_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test unpronouncable words\n",
    "assert(pronouncable(\"T AH T K\", 0.001) == False)\n",
    "assert(pronouncable(\"ER T L\", 0.001) == False)\n",
    "assert(pronouncable(\"S D\", 0.001) == False)\n",
    "assert(pronouncable(\"F NG L T R\", 0.001) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unpronouncable(thresh=0.001):\n",
    "    # Assert all words are returned NOT pronouncable\n",
    "    test_words = [\"T AH T K\", \"ER T L\", \"S D\", \"F NG L T\"]\n",
    "    for w in test_words: assert(pronouncable(w, thresh) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pronouncable(thresh=0.001):\n",
    "    # Assert all words are returned pronouncable\n",
    "    \n",
    "    with open(pickleDumpsPath+syllablesPath, \"rb\") as f:\n",
    "        all_syllables = pickle.load(f)\n",
    "    \n",
    "    random_word = \" \".join(random.choice(all_syllables))\n",
    "    assert(pronouncable(random_word, thresh) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unpronouncable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pronouncable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounable(\"OW S T K T\", 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'K', 'L', 'M', 'NG', 'ER']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"T K L M NG ER\"\n",
    "test_split = nltk.word_tokenize(test)\n",
    "bigramsf = list(ngrams(test_split, 2))\n",
    "test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.04846338687239155, 0.0022081812020376484, 0.0, 0.0]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs = list(map(lambda pair: condProbsDict[pair], bigramsf))\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.004\n",
    "res = all(cond_prob > thresh for cond_prob in cond_probs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'CH',\n",
       " 'D',\n",
       " 'DH',\n",
       " 'F',\n",
       " 'G',\n",
       " 'HH',\n",
       " 'JH',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'NG',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'SH',\n",
       " 'T',\n",
       " 'TH',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'ZH']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_consonants = [i[0] for i in cmudict.phones() if not i[1] == ['vowel']]\n",
    "phoneme_consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(p in phoneme_consonants for p in test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'K', 'L', 'M', 'NG', 'ER']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
