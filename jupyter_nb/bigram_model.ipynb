{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cmudict\n",
    "from nltk import ngrams\n",
    "from nltk import word_tokenize \n",
    "import nltk \n",
    "from itertools import permutations\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_phonemes = [i[0] for i in cmudict.phones()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickleDumps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d20337dfef81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpickleDumpsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"pickleDumps/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msyllablesPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"syllables.pki\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mphonemeCondProbsPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickleDumps\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"phonemeCondProbs.pki\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mbigramsDictPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickleDumpsPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"bigramsDict.pki\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickleDumps' is not defined"
     ]
    }
   ],
   "source": [
    "pickleDumpsPath = \"pickleDumps/\"\n",
    "syllablesPath = \"syllables.pki\"\n",
    "phonemeCondProbsPath = pickleDumps + \"phonemeCondProbs.pki\"\n",
    "bigramsDictPath = pickleDumpsPath + \"bigramsDict.pki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramsDict = dict([(char, 0) for char in accepted_phonemes])\n",
    "#unigramsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible phoneme pairs\n",
    "phoneme_pairs = list(permutations(accepted_phonemes, 2))\n",
    "#phoneme_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of all possible pairs\n",
    "bigramsDict = dict([(char, 0) for char in phoneme_pairs])\n",
    "condProbsDict = dict([(char, 0) for char in phoneme_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickleDumpsPath+syllablesPath, \"rb\") as f:\n",
    "    all_syllables = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in all_syllables:\n",
    "    #line_split = nltk.word_tokenize(line)\n",
    "\n",
    "    # Count unigrams (phonemes)\n",
    "    for phoneme in line:\n",
    "        unigramsDict[phoneme] += 1\n",
    "\n",
    "    # Count bigrams: {\"AH T\" : 1, \"AH K\" : 3, ...}\n",
    "    bigrams = list(ngrams(line, 2))\n",
    "    for bigram in bigrams:\n",
    "        #key = (p1, p2)\n",
    "        #print(key)\n",
    "        if bigram in bigramsDict:\n",
    "            bigramsDict[bigram] += 1\n",
    "        else:\n",
    "            bigramsDict[bigram] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in sorted(unigramsDict, key=unigramsDict.get, reverse=True):\n",
    "#     print (p,\":\", unigramsDict[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p, q in sorted(bigramsDict, key=bigramsDict.get, reverse=True):\n",
    "#     print (p,q,\":\", bigramsDict[(p,q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, p2 in bigramsDict:\n",
    "    count = bigramsDict[(p1, p2)]\n",
    "    cProb = count*1.0 / unigramsDict[p1]\n",
    "    condProbsDict[(p1, p2)] = cProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(phonemeCondProbsPath, \"wb\") as f:\n",
    "    pickle.dump(condProbsDict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "import heapq\n",
    "import cmudict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleDumpsPath = \"pickleDumps/\"\n",
    "phonemeCondProbsPath = pickleDumps + \"phonemeCondProbs.pki\"\n",
    "bigramsDictPath = pickleDumpsPath + \"bigramsDict.pki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(phonemeCondProbsPath, \"rb\") as f:\n",
    "    condProbsDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pronouncable(syllable: str, thresh: float):\n",
    "    \"\"\"\n",
    "    :param syllable: Syllable to test [\"AH K T]\n",
    "    :param thresh: Minimum acceptable value for bigram conditional prob \n",
    "    :returns: True if syllable is pronouncable\n",
    "    \"\"\"\n",
    "    syllable_split = nltk.word_tokenize(syllable)\n",
    "    phoneme_consonants = [i[0] for i in cmudict.phones() if not i[1] == ['vowel']]\n",
    "    if len(syllable_split) == 0: # Emtpy Syllable\n",
    "        return True\n",
    "    if all(p in phoneme_consonants for p in syllable_split):  #No vowel sounds\n",
    "        return False\n",
    "    else:\n",
    "        bigrams = list(ngrams(syllable_split, 2))\n",
    "        # Compute conditional probabilities for phoneme bigrams\n",
    "        cond_probs = list(map(lambda pair: condProbsDict[pair], bigrams))\n",
    "        # Are all cond probs above threshold value\n",
    "        return all(cond_prob > thresh for cond_prob in cond_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test unpronouncable words\n",
    "assert(pronouncable(\"T AH T K\", 0.001) == False)\n",
    "assert(pronouncable(\"ER T L\", 0.001) == False)\n",
    "assert(pronouncable(\"S D\", 0.001) == False)\n",
    "assert(pronouncable(\"F NG L T R\", 0.001) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unpronouncable(thresh=0.001):\n",
    "    # Assert all words are returned NOT pronouncable\n",
    "    test_words = [\"T AH T K\", \"ER T L\", \"S D\", \"F NG L T\"]\n",
    "    for w in test_words: assert(pronouncable(w, thresh) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pronouncable(thresh=0.001):\n",
    "    # Assert all words are returned pronouncable\n",
    "    \n",
    "    with open(pickleDumpsPath+syllablesPath, \"rb\") as f:\n",
    "        all_syllables = pickle.load(f)\n",
    "    \n",
    "    random_word = \" \".join(random.choice(all_syllables))\n",
    "    assert(pronouncable(random_word, thresh) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unpronouncable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pronouncable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronounable(\"OW S T K T\", 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = \"T K L M NG ER\"\n",
    "test_split = nltk.word_tokenize(test)\n",
    "bigramsf = list(ngrams(test_split, 2))\n",
    "test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_probs = list(map(lambda pair: condProbsDict[pair], bigramsf))\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.004\n",
    "res = all(cond_prob > thresh for cond_prob in cond_probs)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'CH',\n",
       " 'D',\n",
       " 'DH',\n",
       " 'F',\n",
       " 'G',\n",
       " 'HH',\n",
       " 'JH',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'NG',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'SH',\n",
       " 'T',\n",
       " 'TH',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'ZH']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_consonants = [i[0] for i in cmudict.phones() if not i[1] == ['vowel']]\n",
    "phoneme_consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"a\"\n",
    "y = list(ngrams(x, 2))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
